---
title: "811257709 FML ASSIGNMENT 2"
author: 'SIVA SAI MADHUMITHA KOTALA '
date: "2023-10-01"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Summary
The goal of the assignment is to forecast, using KNN(k-Nearest Neighbors)Classification, if the loan offer will be accepted by Universal Bank's customers. The dataset includes customer demographic data as well as other cilent-related details. The dataset is first read, the necessary libraries are installed, and then unnecessary columns are deleted, category categories are turned to dummy variables, and the data is finally normalized. The dataset was then split into two sets, training and validation, each containing 60% and 40% of the total data.
Using k-NN with k=1, a new customer was classified as either accepting or rejecting a loan offer. The ideal k value, which strikes a balance between overfitting and underfitting, was discovered by evaluating accuracy on the validation set, with k=3 being the best choice. The confusion matrix was created for the validation data with the best k value. The procedure was then repeated using a different data partitioning scheme (50% training, 30% validation, 20% test) to assess the model's generalization performance. Then, confusion matrices between the training, validation, and test sets were compared.

# Problem Statement
Universal bank is a young bank growing rapidly in terms of overall customer acquisition. The majority of these customers are liability customers (depositors) with varying sizes of relationship with the bank. The customer base of asset customers (borrowers) is quite small, and the bank is interested in expanding this base rapidly in more loan business. In particular, it wants to explore ways of converting its liability customers to personal loan customers.

A campaign that the bank ran last year for liability customers showed a healthy conversion rate of over 9% success. This has encouraged the retail marketing department to devise smarter campaigns with better target marketing. The goal is to use k-NN to predict whether a new customer will accept a loan offer. This will serve as the basis for the design of a new campaign.

The file UniversalBank.csv contains data on 5000 customers. The data include customer demographic information (age, income, etc.), the customer’s relationship with the bank (mortgage, securities account, etc.), and the customer response to the last personal loan campaign (Personal Loan). Among these 5000 customers, only 480 (= 9.6%) accepted the personal loan that was offered to them in the earlier campaign.

Partition the data into training (60%) and validation (40%) sets.

# Data Import and Cleaning

First,we should install the packages like“class”,“caret”,“e1071” and then we should 
call the libraries “class”,“caret”,“e1071”

```{r}
library(class)
library(caret)
```


```{r}
library(e1071)
```


# Reading the data.

```{r}
unibank.info<- read.csv("C:/Users/Lenovo/Desktop/UNIBANK/UniversalBank.csv")
dim(unibank.info)
```

```{r}
head(unibank.info)
```
```{r}
tail(unibank.info)
```

```{r}
t(t(names(unibank.info ))) # The t function creates a transpose of the dataframe
```
        
# Drop ID and ZIP attributes for the dataset

```{r}
new.info<- unibank.info[,-c(1,5)]
dim(new.info)
```
# converting education attribute from int to char
```{r}
new.info$Education <- as.factor(new.info$Education)
```

# creating the dummy variables for the “education” attribute
```{r}
dummy1<- dummyVars(~.,data=new.info)  # This creates the dummy groups
the.info<- as.data.frame(predict(dummy1,new.info))
```


# Setting the seed and dividing the data into training (60%) and validation (40%) sets in case the code needs to be run again.

```{r}
set.seed(1)  # Important to ensure that we get the same sample if we rerun the code
train.info <- sample(row.names(the.info), 0.6*dim(the.info)[1])
valid.info <- setdiff(row.names(the.info), train.info)  
train <- the.info[train.info,]
valid<- the.info[valid.info,]
t(t(names(train)))
```


```{r}
summary(train)
```

```{r}
cat("The size of the training dataset is:" ,nrow(train))
```

```{r}
summary(valid)
```

```{r}
cat("The size of the validation dataset is :",nrow(valid))
```



# Now, let us normalize the data
```{r}
train.norm<- train[,-10] # Note that Personal Income is the 10th variable
valid.norm<- valid[,-10]

norm<- preProcess(train[, -10], method=c("center", "scale"))
train.norm<- predict(norm, train[, -10])
valid.norm<- predict(norm, valid[, -10])
```



# Questions

# Consider the following customer:

1.Age = 40, Experience = 10, Income = 84, Family = 2, CCAvg = 2, Education_1 = 0, Education_2 = 1, Education_3 = 0, Mortgage = 0, Securities Account = 0, CD Account = 0, Online = 1, and Credit Card = 1. Perform a k-NN classification with all predictors except ID and ZIP code using k = 1. Remember to transform categorical predictors with more than two categories into dummy variables first. Specify the success class as 1 (loan acceptance), and use the default cutoff value of 0.5. How would this customer be classified?

# Let's create a new sample
```{r}
new.customer<- data.frame(
  Age = 40,
  Experience = 10,
  Income = 84,
  Family = 2,
  CCAvg = 2,
  Education.1 = 0,
  Education.2 = 1,
  Education.3 = 0,
  Mortgage = 0,
  Securities.Account = 0,
  CD.Account = 0,
  Online = 1,
  CreditCard = 1
)

# Normalize the new customer
customer.norm <- predict(norm, new.customer)
```

Now, let us Predict using KNN Classification
```{r}
pred<- class::knn(train = train.norm, 
                  test = customer.norm, 
                  cl = train$Personal.Loan, k = 1)
pred
```
2.What is a choice of k that balances between over fitting and ignoring the predictor information?
```{r}
# Calculate the accuracy for each value of k
# Set the range of k values to consider
accuracy1<- data.frame(k = seq(1, 15, 1), overallaccuracy = rep(0, 15))
for(i in 1:15) {
  knn.pred1 <- class::knn(train = train.norm, 
                         test = valid.norm, 
                         cl = train$Personal.Loan, k = i)
  accuracy1[i, 2] <- confusionMatrix(knn.pred1, 
                                       as.factor(valid$Personal.Loan),positive = "1")$overall[1]
}

which(accuracy1[,2] == max(accuracy1[,2])) 
```


```{r}
accuracy1
```
The best performing k in the range of 1 to 15 is 3.This k balances over fitting and ignoring predictions, and
is the most accurate for 3

```{r}
plot(accuracy1$k,accuracy1$overallaccuracy)
```

3.Show the confusion matrix for the validation data that results from using the best k.
```{r}
# Creating the confusion matrix

pred <- class::knn(train = train.norm,
test = valid.norm,
cl = train$Personal.Loan, k=3)

confusionMatrix(pred,as.factor(valid$Personal.Loan))

```
           

4.Consider the following customer: Age = 40, Experience = 10, Income = 84,Family = 2, CCAvg = 2, Education_1 = 0, Education_2 =1, Education_3 = 0,Mortgage = 0, Securities Account = 0, CD Account = 0, Online = 1 and Credit Card = 1. Classify the customer using the best k.

Now creating the 2nd new customer dataset
```{r}

customer2.df <- data.frame(
Age = 40,
Experience = 10,
Income = 84,
Family = 2,
CCAvg = 2,
Education.1 = 0,
Education.2 = 1,
Education.3 = 0,
Mortgage = 0,
Securities.Account = 0,
CD.Account = 0,
Online = 1,
CreditCard = 1)
#Normalizing the 2nd customer dataset
cust_norm2 <- predict(norm , customer2.df)

```

5.Repeating the process by partitioning the data into three parts -
50%, 30%, 20%,Apply the k-NN method with the k chosen above. Compare the
confusion matrix of the test set with that of the training and validation sets.
Comment on the differences and their reason.

```{r}
set.seed(400)
Train_Index <- sample(row.names(the.info), .5*dim(the.info)[1])#create train index

#create validation index
Val_Index <- sample(setdiff(row.names(the.info),Train_Index),.3*dim(the.info)[1])
Test_Index =setdiff(row.names(the.info),union(Train_Index,Val_Index))#create test index
train.df <- the.info[Train_Index,]
cat("The size of the new training dataset is:", nrow(train.df))
```
```{r}
valid.df <- the.info[Val_Index, ]
cat("The size of the new validation dataset is:", nrow(valid.df))
```

```{r}
test.df <- the.info[Test_Index, ]
cat("The size of the new test dataset is:", nrow(test.df))
```


# Data Normalizing
```{r}
norm.values <- preProcess(train.df[, -10], method=c("center", "scale"))
train.df.norm <- predict(norm.values, train.df[, -10])
valid.df.norm <- predict(norm.values, valid.df[, -10])
test.df.norm <- predict(norm.values, test.df[,-10])
```

# Performing kNN and creating confusion matrix on training, testing, validation data
```{r}
pred3 <- class::knn(train = train.df.norm,
test = test.df.norm,
cl = train.df$Personal.Loan, k=3)
confusionMatrix(pred3,as.factor(test.df$Personal.Loan))
```


```{r}
pred4 <- class::knn(train = train.df.norm,
test = valid.df.norm,
cl = train.df$Personal.Loan, k=3)
confusionMatrix(pred4,as.factor(valid.df$Personal.Loan))
```

```{r}
pred5 <- class::knn(train = train.df.norm,
test = train.df.norm,
cl = train.df$Personal.Loan, k=3)
confusionMatrix(pred5,as.factor(train.df$Personal.Loan))
```
